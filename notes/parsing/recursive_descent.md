# Recursive Descent Parsing
There are two basic approaches to parsing programs using context free grammars - top down and bottom up.

The top down approach, which we discuss here, proceeds by scanning the string to be parsed from left to right
and constructing the parse tree using a top-down left-to-right depth first search traveral of the tree. This
corresponds to a leftmost derivation of the string and at each derivation step we need to pick which of the
rules for the left most nonterminal we should use.

The bottom up approach corresponds to rightmost derivation of the string and builds the tree from the bottom up.
This is similar to performing a postfix traversal of the parse tree.  

The algorithm for recursive descent parsing is straightforward. 

We generate a leftmost derivation $S_0,\ldots,S_n$ of the string $\omega$ as follows:
* let $S_0$ be the sentential form consisting of the start symbol $S$
* in the $i$ th step, let $k$ be the position of the first non-terminal $N$ in the sentential form $S_i$
  * the first $k-1$ characters in $S_i$ must match the first $k-1$ characters of $\omega$. Let $c=\omega[k]$ be the next character.
  * **use $c$ to determine which of the grammar rules for $N$ should be used next** (We'll talk about how to do this next!)
  * replace $N$ with the left hand side of the chosen grammar rule and extend the parse tree by adding the LHS of the rule as the children of $N$
* continue until $S_n = \omega$

The key point that makes recursive descent parsing work is if we can determine which production to use next by looking at the next character to be parsed.

## LL(0) grammars
The simplest kind of grammar to parse is one where each production for a given non-terminal starts with a different terminal! These are called LL(0)
grammars.

Let's look at an example from the book.

```
S -> if E then S else S
S -> begin S L
S -> print E
L -> end
L -> ; S L
E -> num
```
Here 
* the terminals are ```if, then, else, begin, print, end, num, ';', '-'``` and
* the nonterminals are $\\{S,L,E\\}$

Let's see how to parse a string, say
```
if num then begin print num ; print num end else print num
```
The start symbol is S and the first token is "if" so we know to use the first production
```
S -> if E then S else S
```
next we need to expand parse an E and there is only one rule so we get
```
S -> if num then S else S
```
and now we need to parse an S, and the next token is 'begin' so we use the 2nd rule
```
S -> if num then begin S L else S
```
and so on... at each point we look at the leftmost non-terminal and the next token.
Since each rule for each non-terminal starts with a terminal and those terminals are all different,
we know which rule to use!  We could also build up a parse tree as we go along.

[Here is some code to create the parse tree in Python](./demo1.py)


## LL(1) grammars
We can still use the same approach even if the grammar rules don't all start with terminals that are distinct for each non-terminal.
We just need to know that the first characters which can be generated by those rules are distinct, and that will let us pick the rule!
These are called LL(1) grammars.

To be able to pick the rule to use to rewrite a nonterminal, we need to know the possible terminals that can start a string generated from a non-terminal S.
Let's define the following functions, then we'll show how to compute them, and how to use them in an LL(1) parser:

```
first(S) = the set of all terminals that can begin a string derived from the nonterminal S
nullable(S) = a boolean value which is true if S can drive the empty string
follow(S) = the set of all terminals that can follow the non-terminal S in any sentential form generated from the start symbol
```

### Nullable[S]
To calculate nullable(S) for all S, first set nullable(S) to be false for all S.

Then for each rule $S\rightarrow T_1\ldots T_k$
* if $k=0$, that is if $S\rightarrow \epsilon$, set ```nullable(S)=True```
* if $k>0$ and all $T_i$ are nullable, again set ```nullable(S)=True```

Continue iterating through these rules until there is no change in ```nullable```
* why does this terminate?
* why is it correct?

### First[S]
To calculate first and follow we use a similar iterative process.

* set ```first[s]= {}``` for all S initially
* for each production $S\rightarrow X_1\ldots X_n$
  * if $X_1$ is a terminal, add it to ``first[S]``
  * if $X_1$ is a non-terminal, add ```first[X1]``` to ```first[S]```, as anything that can start X1 can also start S
  * if $X_1\ldots X_j$ are nullable, then add first[ $X_{j+1}$ ] to ```first[S]```, do this for each j from 1 to k

Repeat these steps until there is no longer any change in ```first[s]``` for any s

Continue iterating through these rules until there is no change in ```nullable```
* why does this terminate?
* why is it correct?

We can easily generalize First to a sequence of terminals and nonterminals
* first[ $X_1\ldots X_k$  ] = first( $X_1$ ) if $X_1$ is not nullable
* first[ $X_1\ldots X_k$  ] = first( $X_1$ ) union first( $X_2\ldots X_k$ ) if $X_1$ is nullable

### Follow[S]
Set it to the empty set intially for each nonterminal S, then iterate the following steps until there is no change in any follow set

* for each rule and each pair $i,j$ of positions in the rule,
  * $X\rightarrow X_1\ldots X_i\; X_{i+1}\ldots X_{j-1} \; X_j \ldots X_k$
  * if $X_{i+1}\ldots X_{k}$ are nullable, add follow[ $X$ ] to  follow[ $X_i$ ]
  * if $X_{i+1}\ldots X_{j-1}$ are nullable, add first[ $X_j$ ] to  follow[ $X_i$ ]

Continue iterating through these rules until there is no change in ```nullable```
* why does this terminate?
* why is it correct?

## LL(1) Predictive Parsers
Once we have found the first and follow and nullable sets for each nonterminal, we can easily create a predictive parsers as we did in the LL(0) example above.

The idea is to create a table, useRule, whose rows are the non-terminals and whose columns are the terminal.
For each production $p$ which has the form $S\rightarrow \gamma$  for some (possibly empty) sequence $\gamma$ of terminals and non-terminals

* for each $T$ in first[ $\gamma$ ] we add $p$ to row $S$ and column $T$ of the table,
* if $\gamma$ is nullable, we add $p$ to row $S$ and column $T$ for each $T$ in follow[S]

```useRule[S,T]``` will be a set of productions that we can use to expand nonterminal S when the next token is T.

If this rule has any entries with more than one rule, then it is not LL(1) and can't be used for an LL(1) parser.  We can generalize the operations above
and look for the first $k$ symbols starting a production rather than the first symbol, and likewise construct a LL(k) table, but these are usually too large to be useful.

One we have the useRule table built, we can parse any string just as in the LL(0) example above.

## Example.
Let's try the Grammar 3.12 example from the book ..
```
Z -> d
Z -> X Y Z
Y ->
Y -> X
X -> Y
X -> a
```
and lets compute nullable, first, and follow to get the parser in Figure 3.14.



## Drawbacks and Work arounds
Some common grammars have features that make them non-LL(1), but we can usually find workarounds..

### Left Recursion
One major problem is that any grammar that is left-recursive can not be LL(1). That is if we can find a leftmost derivation starting with $L$ that create a new sentential form also starting with $L$, then the grammar is left recursive. 

Alas, this is pretty common, e.g. addition is left associative and so the natural grammar rule to use is
* $S \rightarrow E \$$
* $E \rightarrow E + T$
* $E \rightarrow T$
* $T \rightarrow id$
* $T \rightarrow num$

We can remove the left recursion, by introducing a new nontermial E'
* $S \rightarrow E \$$
* $E \rightarrow T E'$
* $E' \rightarrow + T E'$
* $E' \rightarrow \epsilon$
* $T \rightarrow id$
* $T \rightarrow num$

and this will be an LL(1) grammar. Some parser generators allow rules with the star operator
* $E \rightarrow T (+ T)*$

which is implemented with this transformation under the hood.

## Left factoring
Another issue is when two productions have the same prefix, e.g.
* S -> if E then S
* S -> if E then S else S
We can resolve this again by introducing a new nonterminal S' and left-factoring the rules
* S -> if E then S S'
* S' -> else S
* S' -> epsilon

This removes the conflict and can be used to make the grammar LL(1)

Almost all programming languages can be described by an LL(1) grammar, so this is all we need for compiler design.

## Example. 
Let's work through the simple arithmetic expressions grammar from Chapter 3 (Grammar 3.15), to get the First/Follow/Nullable data (Table 3.16)
and the predictive parsing data (Table 3.17).

